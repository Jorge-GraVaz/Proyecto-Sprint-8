{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de Viajes — Zuber (Chicago)\n",
    "\n",
    "## Introducción\n",
    "\n",
    "Trabajas como **analista de datos** para **Zuber**, una nueva empresa de viajes compartidos en **Chicago**. El objetivo es identificar **patrones en los datos** para entender el comportamiento de los pasajeros y evaluar cómo factores externos, como el **clima**, influyen en los viajes.\n",
    "\n",
    "---\n",
    "\n",
    "## Base de Datos\n",
    "\n",
    "La base de datos contiene información histórica de **viajes en taxi en Chicago** y está compuesta por las siguientes tablas:\n",
    "\n",
    "### `neighborhoods`\n",
    "\n",
    "Información de los barrios.\n",
    "\n",
    "* `name`: nombre del barrio\n",
    "* `neighborhood_id`: identificador del barrio\n",
    "\n",
    "### `cabs`\n",
    "\n",
    "Información de los vehículos.\n",
    "\n",
    "* `cab_id`: identificador del taxi\n",
    "* `vehicle_id`: ID técnico del vehículo\n",
    "* `company_name`: empresa propietaria\n",
    "\n",
    "### `trips`\n",
    "\n",
    "Información de los viajes.\n",
    "\n",
    "* `trip_id`: identificador del viaje\n",
    "* `cab_id`: taxi que realiza el viaje\n",
    "* `start_ts`: inicio del viaje (redondeado a la hora)\n",
    "* `end_ts`: fin del viaje (redondeado a la hora)\n",
    "* `duration_seconds`: duración del viaje en segundos\n",
    "* `distance_miles`: distancia en millas\n",
    "* `pickup_location_id`: barrio de origen\n",
    "* `dropoff_location_id`: barrio de destino\n",
    "\n",
    "### `weather_records`\n",
    "\n",
    "Información meteorológica.\n",
    "\n",
    "* `record_id`: identificador del registro\n",
    "* `ts`: fecha y hora del registro (redondeado a la hora)\n",
    "* `temperature`: temperatura registrada\n",
    "* `description`: descripción del clima\n",
    "\n",
    "---\n",
    "\n",
    "## Consideraciones\n",
    "\n",
    "No existe una relación directa entre `trips` y `weather_records`. Para combinarlas, se utilizará la **hora de inicio del viaje** (`trips.start_ts`) y la **hora del registro meteorológico** (`weather_records.ts`).\n",
    "\n",
    "---\n",
    "\n",
    "## Objetivos del Análisis\n",
    "\n",
    "### Análisis Exploratorio (Ejercicios 1–3)\n",
    "\n",
    "* Explorar las tablas y sus relaciones.\n",
    "* Analizar patrones de viajes y empresas.\n",
    "* Identificar tendencias relevantes.\n",
    "\n",
    "### Prueba de Hipótesis (Ejercicios 4–6)\n",
    "\n",
    "Evaluar la siguiente hipótesis:\n",
    "\n",
    "> **La duración de los viajes desde el Loop hasta el Aeropuerto Internacional O'Hare cambia durante los sábados lluviosos.**\n",
    "\n",
    "Se compararán las duraciones de los viajes bajo distintas condiciones climáticas para validar estadísticamente la hipótesis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Imprime el campo company_name. Encuentra la cantidad de viajes en taxi para cada compañía de taxis para el 15 y 16 de noviembre de 2017, asigna al campo resultante el nombre trips_amount e imprímelo también. Ordena los resultados por el campo trips_amount en orden descendente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "SELECT \n",
    "    cabs.company_name,\n",
    "    COUNT(trips.trip_id) AS trips_amount\n",
    "FROM trips\n",
    "JOIN cabs ON trips.cab_id = cabs.cab_id\n",
    "WHERE trips.start_ts BETWEEN '2017-11-15 00:00:00' AND '2017-11-16 23:59:59'\n",
    "GROUP BY cabs.company_name\n",
    "ORDER BY trips_amount DESC;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Encuentra la cantidad de viajes para cada empresa de taxis cuyo nombre contenga las palabras \"Yellow\" o \"Blue\" del 1 al 7 de noviembre de 2017. Nombra la variable resultante trips_amount. Agrupa los resultados por el campo company_name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "SELECT \n",
    "    cabs.company_name,\n",
    "    COUNT(trips.trip_id) AS trips_amount\n",
    "FROM trips\n",
    "JOIN cabs ON trips.cab_id = cabs.cab_id\n",
    "WHERE (cabs.company_name LIKE '%Yellow%' OR cabs.company_name LIKE '%Blue%') \n",
    "    AND trips.start_ts BETWEEN '2017-11-01 00:00:00' AND '2017-11-07 23:59:59'\n",
    "GROUP BY cabs.company_name;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Del 1 al 7 de noviembre de 2017, las empresas de taxis más populares fueron Flash Cab y Taxi Affiliation Services. Encuentra el número de viajes de estas dos empresas y asigna a la variable resultante el nombre trips_amount. Junta los viajes de todas las demás empresas en el grupo \"Other\". Agrupa los datos por nombres de empresas de taxis. Asigna el nombre company al campo con nombres de empresas de taxis. Ordena el resultado en orden descendente por trips_amount."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "SELECT \n",
    "    CASE \n",
    "        WHEN cabs.company_name = 'Flash Cab' THEN 'Flash Cab'\n",
    "        WHEN cabs.company_name = 'Taxi Affiliation Services' THEN 'Taxi Affiliation Services'\n",
    "        ELSE 'Other'\n",
    "    END AS company,\n",
    "    COUNT(trips.trip_id) AS trips_amount\n",
    "FROM trips\n",
    "JOIN cabs ON trips.cab_id = cabs.cab_id\n",
    "WHERE trips.start_ts BETWEEN '2017-11-01 00:00:00' AND '2017-11-07 23:59:59'\n",
    "GROUP BY company\n",
    "ORDER BY trips_amount DESC;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Recupera los identificadores de los barrios de O'Hare y Loop de la tabla neighborhoods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "SELECT \n",
    "    neighborhood_id, \n",
    "    name\n",
    "FROM neighborhoods\n",
    "WHERE name IN ('O''Hare', 'Loop');\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Para cada hora recupera los registros de condiciones meteorológicas de la tabla weather_records. Usando el operador CASE, divide todas las horas en dos grupos: Bad si el campo description contiene las palabras rain o storm, y Good para los demás. Nombra el campo resultante weather_conditions. La tabla final debe incluir dos campos: fecha y hora (ts) y weather_conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "SELECT \n",
    "    ts,\n",
    "    CASE\n",
    "        WHEN description ILIKE '%rain%' OR description ILIKE '%storm%' \n",
    "            THEN 'Bad'\n",
    "        ELSE 'Good'\n",
    "    END AS weather_conditions\n",
    "FROM weather_records\n",
    "ORDER BY ts;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Recupera de la tabla de trips todos los viajes que comenzaron en el Loop (pickup_location_id: 50) el sábado y terminaron en O'Hare (dropoff_location_id: 63). Obtén las condiciones climáticas para cada viaje. Utiliza el método que aplicaste en la tarea anterior. Recupera también la duración de cada viaje. Ignora los viajes para los que no hay datos disponibles sobre las condiciones climáticas.\n",
    "\n",
    "Las columnas de la tabla deben estar en el siguiente orden:\n",
    "\n",
    "* `start_ts`\n",
    "* `weather_conditions`\n",
    "* `duration_seconds`\n",
    "* `Ordena por trip_id`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "SELECT \n",
    "    trips.start_ts,\n",
    "    CASE\n",
    "        WHEN weather_records.description ILIKE '%rain%' OR weather_records.description ILIKE '%storm%' \n",
    "            THEN 'Bad'\n",
    "        ELSE 'Good'\n",
    "    END AS weather_conditions,\n",
    "    trips.duration_seconds\n",
    "FROM trips\n",
    "JOIN weather_records\n",
    "    ON trips.start_ts = weather_records.ts\n",
    "WHERE trips.pickup_location_id = 50\n",
    "  AND trips.dropoff_location_id = 63\n",
    "  AND EXTRACT(DOW FROM trips.start_ts) = 6\n",
    "  ORDER BY t.trip_id;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis exploratorio de datos (Python)\n",
    "\n",
    "Además de los datos que recuperaste en las tareas anteriores, ahora tienes un segundo archivo. En total cuentas con dos CSV:\n",
    "\n",
    "- **/datasets/project_sql_result_01.csv**  \n",
    "  Contiene los siguientes datos:  \n",
    "  - `company_name`: nombre de la empresa de taxis  \n",
    "  - `trips_amount`: número de viajes de cada compañía de taxis el 15 y 16 de noviembre de 2017  \n",
    "\n",
    "- **/datasets/project_sql_result_04.csv**  \n",
    "  Contiene los siguientes datos:  \n",
    "  - `dropoff_location_name`: barrios de Chicago donde finalizaron los viajes  \n",
    "  - `average_trips`: promedio de viajes que terminaron en cada barrio en noviembre de 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tareas a realizar\n",
    "1. Importar los archivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Jorge-GraVaz/Proyecto-Sprint-8/datasets/project_sql_result_01.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m stats\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Importar datasets\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m df_companies = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mJorge-GraVaz/Proyecto-Sprint-8/datasets/project_sql_result_01.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m df_neighborhoods = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mJorge-GraVaz/Proyecto-Sprint-8/datasets/project_sql_result_04.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Vista rápida para confirmar que se cargaron correctamente\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\georg\\anaconda3\\envs\\sql_env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\georg\\anaconda3\\envs\\sql_env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\georg\\anaconda3\\envs\\sql_env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\georg\\anaconda3\\envs\\sql_env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\georg\\anaconda3\\envs\\sql_env\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'Jorge-GraVaz/Proyecto-Sprint-8/datasets/project_sql_result_01.csv'"
     ]
    }
   ],
   "source": [
    "# Librerías principales para análisis de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Librerías para visualización\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Librerías para estadística e hipótesis\n",
    "from scipy import stats\n",
    "\n",
    "# Importar datasets\n",
    "df_companies = pd.read_csv('Jorge-GraVaz/Proyecto-Sprint-8/datasets/project_sql_result_01.csv')\n",
    "df_neighborhoods = pd.read_csv('Jorge-GraVaz/Proyecto-Sprint-8/datasets/project_sql_result_04.csv')\n",
    "\n",
    "# Vista rápida para confirmar que se cargaron correctamente\n",
    "print(\"Empresas de taxis:\")\n",
    "print(df_companies.head(), \"\\n\")\n",
    "\n",
    "print(\"Barrios de destino:\")\n",
    "print(df_neighborhoods.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sql_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
